# Проблемы высокопроизводительных вычислений  (продолжение)

## Сложность параллельного кода

Каждый год, из-за продажи новой продукции приходится повышать пиковую производительность (векторизация, многоядерность). Как результат, появляется сложность, измеряемая либо как цикломатическая сложность, либо в строчках кода. Ошибки векторизации (перекрытия по памяти, ошибки по данным, доверие restrict переменным) приводит к понижению качества кода.

LU-разложение на C99 занимает в 5 раз меньше строк кода, чем тоже решение на OpenCL. Это повышает вероятность допустить ошибки.

Возможное решение -- не гетерогенные архитектуры (смешивание вычислительных ядер общего назначения и специфичного назначения (GPU, FPGA, ASIC)).

## Проблема надёжности многоядерных и многопроцессорных архитектур

Увеличение производительности идёт за счёт увеличение числа вычислителей (на текущей элементной базе мы вышли на плато). Но увеличение числа ядер ведёт к критическому снижению надёжности.

Возможно решение -- изменение парадигмы программирования, считать что часть ядер может приводить к неверному решению, но большая часть ядер будет работать верно. Либо распределённые вычисления.